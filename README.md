# AI Security Assurance Labs
### A Hands-On Framework for Model Supply-Chain Security, Static Analysis, and LLM Red Teaming

This repository contains a structured collection of AI Security Assurance modules focused on:

- Model supply-chain verification  
- Model integrity and malware scanning  
- Static analysis of AI/ML artifacts  
- LLM red teaming and automated vulnerability evaluation  
- End-to-end model intake and validation workflows  

The repository demonstrates practical, industry-aligned approaches used in AI Security Engineering.

---

## ğŸ“‚ Repository Structure

```
ai-security-assurance-labs/
â”‚
â”œâ”€â”€ model-supply-chain/   # Model intake, verification, supply-chain security
â”‚
â”œâ”€â”€ red-teaming/          # Automated and manual LLM red teaming
â”‚   â”œâ”€â”€ garak/
â”‚   â””â”€â”€ promptfoo/
â”‚
â”œâ”€â”€ static-analysis/      # Malware, integrity, and rule-based analysis
â”‚   â”œâ”€â”€ clamav/
â”‚   â”œâ”€â”€ hashing/
â”‚   â”œâ”€â”€ sigcheck/
â”‚   â””â”€â”€ yara/
â”‚
â””â”€â”€ README.md             # Main repository documentation
```

---

## ğŸ¯ Purpose

The repository provides a complete example of an AI Security Assurance workflow, including:

- Secure model download and intake  
- Detection of tampered or malicious model files  
- Static malware scanning and pattern matching  
- Verification of binary signatures and model integrity  
- Automated LLM red teaming and vulnerability discovery  

The structure aligns with practices used by AI Security teams, ML Ops groups, and AI governance functions.

---

## ğŸ§© High-Level Architecture

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Model Supply Chain  â”‚
      â”‚   (Intake + Verify) â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Static Analysis Layer   â”‚
     â”‚ YARA â€¢ ClamAV â€¢ Hashing â”‚
     â”‚ Sigcheck â€¢ Metadata     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Red Teaming & Assessments      â”‚
  â”‚ Garak â€¢ Promptfoo â€¢ PyRIT      â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Secure Deployment /        â”‚
     â”‚ Model Certification         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each repository module corresponds to one layer of this security pipeline.

---

## ğŸ” Module Overview

### **1. Model Supply Chain Security**
ğŸ“ `model-supply-chain/`

Includes:

- Model intake workflow  
- Verification and provenance stages  
- Trusted source validation  
- Hash integrity checks  
- Storage hygiene and evidence retention  

---

### **2. Static Analysis**
ğŸ“ `static-analysis/`

| Module      | Description |
|-------------|-------------|
| **ClamAV**   | Malware signature scanning for `.gguf`, `.safetensors`, and tokenizer files |
| **Hashing**  | SHA-256 integrity verification |
| **Sigcheck** | Binary signature validation |
| **YARA**     | Rule-based detection of suspicious or anomalous content |

---

### **3. LLM Red Teaming**
ğŸ“ `red-teaming/`

| Tool        | Purpose |
|-------------|---------|
| **Garak**     | Automated LLM vulnerability scanning |
| **Promptfoo** | Config-driven prompt testing and red teaming |

---

## ğŸš€ Workflow Summary

### **Model Intake**
Performed through trusted sources such as HuggingFace CLI, GitHub releases, or Ollama.

### **Static Analysis Sequence**
1. Sigcheck  
2. Hash integrity verification  
3. YARA scanning  
4. ClamAV scanning  

### **Red Teaming**
Evaluation using Garak and Promptfoo to identify jailbreak, prompt injection, and unsafe output patterns.

### **Documentation**
Markdown reports and evidence are stored in the repository as templates and examples.

---

## ğŸ”— Navigation

- Model Supply Chain  
  https://github.com/fred-ai-security/ai-security-assurance-labs/tree/main/model-supply-chain

- Static Analysis  
  https://github.com/fred-ai-security/ai-security-assurance-labs/tree/main/static-analysis

- Red Teaming  
  https://github.com/fred-ai-security/ai-security-assurance-labs/tree/main/red-teaming

---

## ğŸ›¡ï¸ Tools Represented

- Sigcheck (Sysinternals)  
- ClamAV Antivirus Engine  
- YARA Rule Engine  
- PowerShell SHA-256 hashing  
- Garak LLM Red Teaming Toolkit  
- Promptfoo Red Team Engine  
- Model intake integrity workflows  

---

This repository serves as a comprehensive AI Security Assurance reference implementation covering supply-chain validation, static analysis, and adversarial testing.
